---
title: "Germany's Solar Power Generation (2015-2019)"
author: "Santoro Arnaldo mat:822274"
date: "05 settembre 2019"
output: beamer_presentation
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## Power Generation Growth

- Photovoltaics is a fast growing market: The Compound Annual Growth
Rate (CAGR) of PV installations was 24% between year 2010 to 2017.

- Concerning PV module production in 2017, China&Taiwan hold the lead
with a share of 70%, followed by Rest of Asia-Pacific & Central Asia
(ROAP/CA) with 14.8%. Europe contributed with a share of 3.1%
(compared to 4% in 2016); USA/CAN contributed 3.7%.

- In 2017, Europe’s contribution to the total cumulative PV installations
amounted to 28% (compared to 33% in 2016). In contrast, installations in
China accounted for 32% (compared to 26% in 2016).

Copyright: Fraunhofer ISE: Photovoltaics Report, updated: 14 March 2019

---


## Power Generation Growth

![https://en.wikipedia.org/wiki/Solar_power](C:\Users\Lenovo\Pictures\Solar_power_growth.png)



---

## European horizontal irradiation

![https://en.wikipedia.org/wiki/Solar_power](C:\Users\Lenovo\Pictures\Global_horizontal_irradiation.png)

---

## Solar Power in Germany

- Germany has about the same solar potential as Fairbanks, Alaska (Source: NREL, based on an average of 30 years of weather data).

- In 2018, Germany accounted for about 9% (45.4 GWp) of the cumulative
PV capacity installed worldwide (515 GWp) with about 1.7 million PV
systems installed in Germany. In 2018 the newly installed capacity in
Germany was about 3.0 GWp; in 2017 it was 1.7 GWp.

- PV covered about 7% of Germany’s electricity demand in 2017.
Renewable sources delivered about 38% of the total net power
consumption in 2017 in Germany.

- In 2017 about 19 Mio. t CO2 emissions have been avoided due to
38.4 TWh electrical energy generated by PV in Germany.

- PV system performance has strongly improved. Before 2000 the typical
Performance Ratio was about 70%, while today it is in the range of
80% to 90%.

Copyright: Fraunhofer ISE: Photovoltaics Report, updated: 14 March 2019

---

## Solar Power in Germany

![https://en.wikipedia.org/wiki/Solar_power_in_Germany](C:\Users\Lenovo\Pictures\Solar-energy-factsheet-germany.jpg)

---

## Solar Park in Meuro

![Meuro and Schipkau, Germany 2012](C:\Users\Lenovo\Pictures\Senftenberg_Phoenix_Solar_AG.jpg)

 

---

## Dataset Documentation

![Variables of the Dataset](C:\Users\Lenovo\Pictures\Data_variables.png)


---

## Dataset Documentation

![Variables of the Dataset](C:\Users\Lenovo\Pictures\load_schema.png)


---

## Dataset

```{r , include=FALSE,echo=FALSE}
library(dplyr)
library(fpp)
library(fpp2)
library(lubridate)
#the following file holds hourly data on solar power national generation and solar power capacity in MWh
#from date 01/01/2015 till 09/01/2019
solar.de <- read.csv("german_solar_capacity_actual_01012015-09012019.csv")

generation.de <-ts(solar.de$DE_solar_generation_actual)

# To ease the analysis the data is transformed from hourly to daily by taking the daily mean.

hourly.to.daily <- function(dataset, column){
  output <- c()
  for (i in 1:(length(dataset))/24 ){
    n <- 0
    for (j in 1:24){
      n <- n + dataset[ (i-1) * 24 + j ]
    }
    output[i] = n/24.0
  }
  return(output)
}

daily.gen.de <- hourly.to.daily(generation.de)

daily.to.monthly <-function(dataset, set.dates){
  
  monthly.temp <-c()
  monthly.dates <- format(set.dates, format="%Y-%m")
  i <- 1
  j <- 2
  
  monthly.temp[i] = dataset[i]
  for (k in 2:length(dataset)){
    if(monthly.dates[k]==monthly.dates[k-1]){
      monthly.temp[i] <- monthly.temp[i] + dataset[k]
      j = j + 1
    }
    else{
      monthly.temp[i] = monthly.temp[i]/j
      j = 1
      i = i+1
      monthly.temp[i] <- dataset[k]
      
    }
    
    
  }
  monthly.temp[i] <- monthly.temp[i]/9
  return (monthly.temp)
}

start.date.de <- as.Date(solar.de$cet_cest_timestamp[1])
dates.de <- start.date.de + 0:(length(daily.gen.de)-1)
monthly.gen.de <- daily.to.monthly(daily.gen.de, dates.de)
monthly.dates.de <- format(dates.de, format="%Y-%m")
monthly.gen.de <- ts(monthly.gen.de, frequency = 12, start = c(2015,1))
train <- subset(monthly.gen.de, end=length(monthly.gen.de)-5)
test <- subset(monthly.gen.de, start=length(monthly.gen.de)-4)
monthly.dec <- stl(train, s.window="periodic")

```
Problems with the dataset:

- Vast majority of solar data from 2005 to 2019 is NA.

- Data uses a different scale adjustment from 2005 till 2014.

- For these reasons the data used for this project goes from 2015 to 2019.

Data manipulation:

- Data was transformed from hourly to monthly. Last month of the test has only 9 observation avaliable, so its information is less reliable.

- The dataset was divided into train and test, using only the last 5 months for validation.

- Log transformation results very useful in energy production data, but Box-Cox transformations didn't result very useful, probably because of to few data, so readability was preferred.

---

## Dataset

```{r echo=FALSE, include=TRUE}
ggtsdisplay(train, main= "Germant Solar Generation 2015-18")
```

---

## STL Decomposition
Stands for Seasonal and Trend decomposition using loess

- loess is a kind of filter

- Seasonality found by loess smoothing on the seasonal sub-series (all Jan values, all Feb values,...): $loess(y_t) = \hat{s_t}$

- Seasonality is removed: $\hat{t_t + e_t} = y_t - \hat{s_t}$

- The Trend is found by smoothing the remainder: $loess(\hat{t_t + e_t}) = \hat{t_t}$

- The remainder component is the residuals from the seasonal plus trend fit: $\hat{e_t} = y_t - \hat{t_t} + \hat{s_t}$.

- This method provides values for $\hat{t_t}, \hat{s_t}, \hat{r_t}, t \in \{0, ... , \lfloor p/2 \rfloor - 1\}$ not provided by `decompose` function.


---

## STL Decomposition


``` {r echo = FALSE}
monthly.dec%>%autoplot(main="Germany's Solar Generation 2015-2018")
```


---

## Auto Arima Algorithm

![](C:\Users\Lenovo\Pictures\auto_arima_algorithm.png)


---

## Auto Arima Algorithm

- The Model Found has been recognized as a $ARIMA(0,1,1)_{12} (0,0,0)$ with drift.

- $\Theta = -0.5840$ with standard error $0.4488$ (!)
- $\delta = 18.1580$ with standard error $6.2926$
- $D = 1$.

Other models were found, mainly to compare them with the automatically chosen one.
They weren't necessairly chosen to be worse. 
Indeed their Parameters have lower standard errors, and their Information criteria are lower too.

---

## Alternative Models

``` {r echo = FALSE, include = FALSE}

#################
# MODEL FITTING #
#################
# 
# model0 <- Arima(train, order=c(0,0,0), seasonal= c(0,1,0))
# # #boxtest ok;
# # #nonstandard residuals
# # #ACF ok
# # #p-value 0.3686
# # #AIC=506.83   AICc=506.97   BIC=508.3
# model1 <- Arima(train, order=c(0,0,0), seasonal= c(1,1,0))
# # # worse results
# # #Box-test fail
# # #nonstandard residuals
# # #ACF ok
# # #p-value 0.2225
# # #AIC=508.33   AICc=508.75   BIC=511.27
# model2 <- Arima(train, order=c(0,0,0), seasonal= c(0,1,1))
# # #   worse results
# # #Box-test fail
# # #nonstandard residuals
# # #p-value 0.2192
# # #AIC=508.31   AICc=508.73   BIC=511.24
# model3 <- Arima(train, order=c(0,0,1), seasonal= c(0,1,0))
# # #   worse results
# # #Box-test ok
# # #nonstandard residuals
# # #p-value 0.4693
# # #AIC=507.76   AICc=508.17   BIC=510.69
# #model4 <- Arima(train, order=c(1,0,1), seasonal= c(0,1,0))
# # #   not working
# # model5 <- Arima(train, order=c(1,0,0), seasonal= c(0,1,0))
# # #   worse result
# # #boxtest succeed;
# # #nonstandard residuals
# # #ACF ok
# # #p-value 0.4691
# # #AIC=507.45   AICc=507.87   BIC=510.38
# #As this proceeding will lead to the same results of the automated model, the option to use d=1 is adopted
model6 <- Arima(train, order=c(1,1,0), seasonal= c(0,1,0))
# #   ambiguous result
# #boxtest fail;
# #nonstandard residuals
# #ACF ok
# #p-value 0.1072
# #AIC=497.09   AICc=497.52   BIC=499.96
model7 <- Arima(train, order=c(1,1,1), seasonal= c(0,1,0))
# #   slight improvement
# #boxtest succeed;
# #sufficiently standard residuals
# #ACF ok
# #p-value 0.4994
# #AIC=494.39   AICc=495.28   BIC=498.69
model8 <- Arima(train, order=c(2,0,0), seasonal= c(0,1,0))
# #   worse result
model9 <- Arima(train, order=c(3,0,0), seasonal= c(0,1,0))
# #   worse result
# #boxtest succeed;
# #standard residuals
# #ACF ok
# #p-value 0.7164
# #AIC=507.91   AICc=509.39   BIC=513.77
model10 <- Arima(train, order=c(1,1,2), seasonal= c(0,1,0))
# # slight improvement result
# #boxtest succeed;
# #standard residuals
# #ACF ok
# #p-value 0.4294
# #AIC=496.3   AICc=497.84   BIC=502.04
model11 <- Arima(train, order=c(0,1,1), seasonal= c(1,1,0))
#   improvement
#boxtest succeed;
#standard residuals
#ACF ok
#p-value 0.5913
#AIC=491.66   AICc=492.55   BIC=495.96
model12 <- Arima(train, order=c(0,1,4), seasonal= c(1,1,0))
# NOW ELIMINATE ALL PARAMETERS p SUCH THAT | p/se(p) | > 2
# we return to model11

fit1 <- model6
fit2 <- model11
fit3 <- auto.arima(train, stationary = FALSE, seasonal=TRUE, ic="aicc")
```


```{r echo = FALSE}
fit2
```

```{r echo = FALSE}
fit2
```


---

## Portmanteau Test for Automated model

```{r echo = FALSE}
tsdiag(fit3, lag = 25, gof.lag = 25)
```


---

## Pormanteau Test for Manual Model 1

```{r echo = FALSE}
tsdiag(fit1, lag = 25, gof.lag = 25)
```


---

## Pormanteau Test for Manual Model 2

```{r echo = FALSE}
tsdiag(fit2, lag = 25, gof.lag = 25)
xlab = "Time"
ylab = "MWh"
fc1 <- forecast(fit1 , h=length(test))
p1<- autoplot(fc1, color = "blue",xlab = xlab, ylab=ylab) +  autolayer(fc1, color="blue", lwd=2) + autolayer(test, color="orange", lwd=2 ) + autolayer(train, color="orange", lwd=2)
fc2 <- forecast(fit2 , h=length(test))
p2<-autoplot(fc2, color = "blue", xlab = xlab,ylab=ylab) +  autolayer(fc2, color="blue", lwd=2) + autolayer(test, color="orange", lwd=2) +autolayer(train, color="orange", lwd=2)
fc3 <- forecast(fit3 , h=length(test))
p3<-autoplot(fc3, color = "blue",xlab = xlab, ylab=ylab) +  autolayer(fc3, color="blue", lwd=2) + autolayer(test, color="orange", lwd=2) +autolayer(train, color="orange", lwd=2)
```

---

## h-step ahead Forecasts

5-step ahead forecast for automatic model:
```{r echo = FALSE}
p3
```


---

## Forecasting

5-step ahead forecast for model 1:
```{r echo = FALSE}
p1
```


---

## Forecasting

5-step ahead forecast for model 2:
```{r echo = FALSE}
p2
```


---

## Accuracy of models

The accuracy measures of the models compared with themselves.

The third one is the result of `auto.arima` function.

Mean Absolute Scaled Error ($MASE$) is a scaled error measure.

It is based on $MAE$, the Mean Absolute Error.

Given a model $m$ , $MASE(m) < 1$ means that the forecast is better than an average naive forecast, while $MASE(m) > 1$ means it's worse.

```{r echo = FALSE}
accuracy(fc1,test)
accuracy(fc2,test)
accuracy(fc3,test)
```


---

## Cross Validation


RMSE for model 1, model 2, and the automated model.

```{r echo=FALSE}
my.CV <- function( data, model ){
  train.min <- model$arma[5]*2
  i = 0
  errors <- c()
  while (train.min+i+1 < length(monthly.gen.de) ){
    train <- subset(monthly.gen.de, end = train.min+i)
    
    model.train <- Arima(train, model = model)
    #solar.train %>% forecast(h=12) %>% autoplot() + autolayer(test)
    #accuracy(forecast(solar.train,h=12))
    
    fc <- forecast(model.train, h=1)
    errors[i+1] <- (data[train.min+i+1]-fc$mean[1])^2#RSE
    i<-i+1
  }
  CV.RMSE <- sqrt(sum(errors)/length(errors))
  return(CV.RMSE)
}
my.CV(monthly.gen.de, fit1)
my.CV(monthly.gen.de, fit2)
my.CV(monthly.gen.de, fit3)
```


CV means
A mean different than zero means that forecast is biased

```{r echo=FALSE}
my.CVmean <- function( data, model ){
  train.min <- model$arma[5]*2
  i = 0
  errors <- c()
  while (train.min+i+1 < length(monthly.gen.de) ){
    train <- subset(monthly.gen.de, end = train.min+i)
    
    model.train <- Arima(train, model = model)
    #solar.train %>% forecast(h=12) %>% autoplot() + autolayer(test)
    #accuracy(forecast(solar.train,h=12))
    
    fc <- forecast(model.train, h=1)
    errors[i+1] <- (data[train.min+i+1]-fc$mean[1])#RSE
    i<-i+1
  }
  CV.mean <- mean(errors)
  return(CV.mean)
}
my.CVmean(monthly.gen.de, fit1)
my.CVmean(monthly.gen.de, fit2)
my.CVmean(monthly.gen.de, fit3)
```

## Simulation

Arima simulation with the `auto.arima` model:
```{r echo=FALSE}
simulate(fit3, nsim = 49) %>% autoplot()
```

## Simulation

Arima simulation with model 1:
```{r echo=FALSE}
simulate(fit1, nsim = 49) %>% autoplot()
```

## Simulation

Arima simulation with the model 2:
```{r echo=FALSE}
simulate(fit2, nsim = 49) %>% autoplot()
```

